<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Temporally Consistent Video Transformer for Long-Term Video Prediction</title>

  <style type="text/css"> 
  </style>

  <meta name="author" content="Wilson Yan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>
  <!-- <script>$(document).ready(function(){
    document.getElementById("tab0").click();
  });
  </script> -->
</head>

<body>
  <div class="jumbotron jumbotron-fluid text-center">
    <div class="container"></div>
    <h2>
      Temporally Consistent Video Transformer
      <br>
      for Long-Term Video Prediction
    </h2>
    <hr>
    <p class="authors">
      <a href="https://wilson1yan.github.io/">Wilson Yan</a>, 
      <a href="https://danijar.com/">Danijar Hafner</a>, 
      <a href="https://stepjam.github.io/">Stephen James</a>,
      <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>
    </p>
    <div class="btn-group" role="group" aria-label="Top menu">
      <a class="btn btn-primary" href="TODO" role="button">Paper</a>
      <a class="btn btn-primary" href="https://github.com/wilson1yan/teco" role="button">Code</a>
    </div>
  </div>
  <div class="container">
    <div class="section">
      <h2> Abstract </h2>
      <hr>
      <p>
        Generating long, temporally consistent video remains an open challenge in video generation. 
        Primarily due to computational limitations, most prior methods limit themselves to training 
        on a small subset of frames that are then extended to generate longer videos through a sliding 
        window fashion. Although these techniques may produce sharp videos, they have difficulty 
        retaining long-term temporal consistency due to their limited context length. In this work, 
        we present <b>Te</b>mporally <b>Co</b>nsistent Video Transformer (TECO), a vector-quantized 
        latent dynamics video prediction model that learns compressed representations to efficiently 
        condition on long videos of hundreds of frames during both training and generation. We use a 
        MaskGit prior for dynamics prediction which enables both sharper and faster generations compared 
        to prior work. Our experiments show that TECO outperforms SOTA baselines in a variety of video 
        prediction benchmarks ranging from simple mazes in DMLab, large 3D worlds in Minecraft, and complex 
        real-world videos from Kinetics-600. In addition, to better understand the capabilities of video 
        prediction models in modeling temporal consistency, we introduce several challenging video prediction 
        tasks consisting of agents randomly traversing 3D scenes of varying difficulty. This presents a 
        challenging benchmark for video prediction in partially observable environments where a model 
        must understand what parts of the scenes to re-create versus invent depending on its past 
        observations or generations.
      </p>
    </div>

    <div class="section">
      <h2>DMLab</h2>
      <hr>
      <p><b>Left</b>: Videos of 300 frames conditioned on 144</p>
      <p><b>Right</b>: 3D visualizations of 300 frame videos conditioned on 36 frames. <b>Video predictions use only RGB frames</b></p>
      <div style="width: 100%; overflow: hidden;">
        <div style="width: 49%; float: left;">
                <video width="100%" onended="this.currentTime = 0;" controls="" muted="">				
              <source src="./videos/comparison/dmlab.mp4" type="video/mp4"> 
              </video>
        </div>
        <div style="width: 2%;"> </div>
        <div style="width: 49%; float: right;">
            <video width="100%" onended="this.currentTime = 0;" controls="" muted="">				
            <source src="./videos/comparison/dmlab_3d.mp4" type="video/mp4">
            </video>
        </div>
      </div>

      <br>
      <p><b>Below</b>: Video prediction samples for each method with 300 frames conditioned on 36</p>
      <section id="dmlab" class="bg-light">
      <nav class="nav justify-content-center nav-tabs" id="dmlab-current-view-ul">
          <a class="nav-link active" id="tab0" href="javascript: void(0);" onclick="ChangeCurrentView(0, 0);"><h5>TECO (ours)</h5></a>
          <a class="nav-link" id="tab1" href="javascript: void(0);" onclick="ChangeCurrentView(0, 1);"><h5>Latent FDM</h5></a>
          <a class="nav-link" id="tab2" href="javascript: void(0);" onclick="ChangeCurrentView(0, 2);"><h5>Perceiver AR</h5></a>
          <a class="nav-link" id="tab3" href="javascript: void(0);" onclick="ChangeCurrentView(0, 3);"><h5>CW-VAE</h5></a>
        <a class="nav-link" id="tab4" href="javascript: void(0);" onclick="ChangeCurrentView(0, 4);"><h5>FitVid</h5></a>
      </nav>

      <div id="dmlab_output_canvas" style="width: 100%; overflow: hidden;">
        <div style="width: 49%; float: left;">
          <video id="dmlab_output_video" width="100%" onended="this.currentTime = 0;" controls="" muted="">				
            <source src="./videos/dmlab/teco.mp4" type="video/mp4"> 
          </video>
        </div>
        <div style="width: 2%;"> </div>
        <div style="width: 49%; float: right">
          <video id="dmlab_output_video_3d" width="100%" onended="this.currentTime = 0;" controls="" muted="">				
            <source src="./videos/dmlab/teco_3d.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      </section>

    <br>

    <div class="section">
      <h2>Minecraft</h2>
      <hr>
      <p><b>Below</b>: Videos of 300 frames conditioned on 144</p>
      <center>
      <div style="width: 75%">
            <video width="100%" onended="this.currentTime = 0;" controls="" muted="">				
          <source src="./videos/comparison/minecraft.mp4" type="video/mp4"> 
          </video>
      </div>
      </center>

      <br>
      <p><b>Below</b>: Video prediction samples for each method with 300 frames conditioned on 36</p>
      <section id="minecraft" class="bg-light">
      <nav class="nav justify-content-center nav-tabs" id="minecraft-current-view-ul">
          <a class="nav-link active" id="tab0" href="javascript: void(0);" onclick="ChangeCurrentView(1, 0);"><h5>TECO (ours)</h5></a>
          <a class="nav-link" id="tab1" href="javascript: void(0);" onclick="ChangeCurrentView(1, 1);"><h5>Latent FDM</h5></a>
          <a class="nav-link" id="tab2" href="javascript: void(0);" onclick="ChangeCurrentView(1, 2);"><h5>Perceiver AR</h5></a>
          <a class="nav-link" id="tab3" href="javascript: void(0);" onclick="ChangeCurrentView(1, 3);"><h5>CW-VAE</h5></a>
        <a class="nav-link" id="tab4" href="javascript: void(0);" onclick="ChangeCurrentView(1, 4);"><h5>FitVid</h5></a>
      </ul>

      <center>
      <div id="minecraft_output_canvas" style="width: 75%;">
          <video id="minecraft_output_video" width="100%" onended="this.currentTime = 0;" controls="" muted="">				
            <source src="./videos/minecraft/teco.mp4" type="video/mp4"> 
          </video>
      </div>
      </center>
      </section>

    <script type="text/javascript">
      var currentViewList = ["teco", "latent_fdm", "perceiver_ar", "cwvae", "fitvid"];
      var currentView = "teco";

      function ChangeVideo(dataset, idx){ 
        var method = "";
        if (idx == 0) {method = "teco";}
        if (idx == 1) {method = "latent_fdm";}
        if (idx == 2) {method = "perceiver_ar";}
        if (idx == 3) {method = "cwvae";}
        if (idx == 4) {method = "fitvid";}

        var videoB = document.getElementById(dataset + "_output_video");
        videoB.src = "./videos/" + dataset + "/" + method + ".mp4";
        // videoB.play();

        if (dataset == "dmlab") {
          var videoC = document.getElementById(dataset + "_output_video_3d");
          videoC.src = "./videos/" + dataset + "/" + method + "_3d.mp4";
          // videoC.play();
        }
      }

      function ChangeCurrentView(dataset_idx, idx){
        var dataset = "";
        if (dataset_idx == 0) {dataset = "dmlab";}
        if (dataset_idx == 1) {dataset = "minecraft";}
        if (dataset_idx == 2) {dataset = "habitat";}
        if (dataset_idx == 3) {dataset = "kinetics";}

        var li_list = document.getElementById(dataset + "-current-view-ul").children;
        for(i = 0; i < li_list.length; i++){
          li_list[i].className = "nav-link";
        }
        li_list[idx].className = "nav-link active";
        currentView = currentViewList[idx];
        document.getElementById(dataset + "_output_canvas").style.display = 'block'; 

        ChangeVideo(dataset, idx);
      }
	</script>

  </div>

</body>

</html>
